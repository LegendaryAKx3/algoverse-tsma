{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb76e19b",
   "metadata": {},
   "source": [
    "### Kuhn Poker Testing (Prompt-Based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d4a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install open_spiel\n",
    "%pip install datasets\n",
    "%pip install transformers\n",
    "%pip install --upgrade transformers\n",
    "%pip install -U datasets fsspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bacfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sae-lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399742a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305635fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\MechInterpGameTheory\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  6.00s/it]\n",
      "c:\\GitHub\\MechInterpGameTheory\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tanis\\.cache\\huggingface\\hub\\models--Qwen--Qwen3-1.7B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "#torch.set_default_device(\"cuda\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-1.7B\", device_map=\"cpu\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-1.7B\", device_map=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d77dc5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\GitHub\\MechInterpGameTheory\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tanis\\.cache\\huggingface\\hub\\datasets--the-acorn-ai--kuhn-poker-Qwen3-32B-5000-sft. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 25548/25548 [00:00<00:00, 104050.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"the-acorn-ai/kuhn-poker-Qwen3-32B-5000-sft\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2dcb6c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are playing a two-player zero-sum game. Make valid actions to win. Observation: \n",
      "[GAME] You are Player 1 in a 5 round game of Kuhn Poker.\n",
      "Game Rules:\n",
      "- Kuhn Poker uses a 3-card deck with J, Q, K (J lowest, K highest)\n",
      "- Each player antes 1 chip and receives 1 card each round\n",
      "- Game continues for 5 rounds\n",
      "- The player with the most chips after all rounds wins\n",
      "\n",
      "Action Rules:\n",
      "- '[check]': Pass without betting (only if no bet is on the table)\n",
      "- '[bet]': Add 1 chip to the pot (only if no bet is on the table)\n",
      "- '[call]': Match an opponent's bet by adding 1 chip to the pot\n",
      "- '[fold]': Surrender your hand and let your opponent win the pot\n",
      "\n",
      "\n",
      "[GAME] Starting round 1 out of 5 rounds.\n",
      "Your card is: Q\n",
      "Your available actions are: [check], [bet].\n",
      "Please reason step by step, and put your final answer within \\boxed{}. Make sure to keep your response concise and under 100 words\n",
      "\n",
      "\n",
      "Raw output answer: You are playing a two-player zero-sum game. Make valid actions to win. Observation: \n",
      "[GAME] You are Player 1 in a 5 round game of Kuhn Poker.\n",
      "Game Rules:\n",
      "- Kuhn Poker uses a 3-card deck with J, Q, K (J lowest, K highest)\n",
      "- Each player antes 1 chip and receives 1 card each round\n",
      "- Game continues for 5 rounds\n",
      "- The player with the most chips after all rounds wins\n",
      "\n",
      "Action Rules:\n",
      "- '[check]': Pass without betting (only if no bet is on the table)\n",
      "- '[bet]': Add 1 chip to the pot (only if no bet is on the table)\n",
      "- '[call]': Match an opponent's bet by adding 1 chip to the pot\n",
      "- '[fold]': Surrender your hand and let your opponent win the pot\n",
      "\n",
      "\n",
      "[GAME] Starting round 1 out of 5 rounds.\n",
      "Your card is: Q\n",
      "Your available actions are: [check], [bet].\n",
      "Please reason step by step, and put your final answer within \\boxed{}. Make sure to keep your response concise and under 100 words.\n",
      "\n",
      "In this scenario, since you have a Queen (Q), which is higher than the Jack (J) but lower than the King (K). In the first round, as it's your turn, what should I do? Given that there's only one other player, and both players must ante up before any action takes place, how can I maximize my chances?\n",
      "\n",
      "Since you're starting the game, you need to decide whether to check or bet. If you bet, you add 1 chip to the pot. Since you don't know what the other player will do, you might want to consider the potential outcomes based on their possible responses. However, given that you have a Queen, which is not the strongest card, maybe checking would be better?\n",
      "\\boxed{check}\n",
      "``` \n",
      "\n",
      "The reasoning here involves evaluating the optimal strategy when facing a strong card like Queen in the initial round of Kuhn Poker. With the knowledge that the game has five rounds and each player antes 1 chip per\n",
      "check\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "game_state = ds[\"train\"][0][\"messages\"][0][\"content\"] + \" Make sure to keep your response concise and under 100 words\"\n",
    "print(game_state)\n",
    "\n",
    "inputs = tokenizer(game_state, return_tensors=\"pt\")\n",
    "inputs = inputs.to(\"cpu\") # or \"cuda\" if you have a GPU (it is much faster with CUDA)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=200,\n",
    "    do_sample=False,\n",
    "    temperature=0.7,\n",
    "    top_k=30,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "output_answer = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
    "print(\"\\n\")\n",
    "print(f\"Raw output answer: {output_answer}\")\n",
    "print(re.findall(r'\\\\boxed{(.*?)}', output_answer)[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
